ğŸ¬ CineMind â€” Multimodal Movie Intelligence Platform


AI-powered system for analyzing movies using video, audio, and text to extract scene-level engagement intelligence.

ğŸŒŸ Overview

CineMind is a multimodal AI backend system that converts raw movie files into structured, scene-level intelligence.
It analyzes visual structure, audio emotion, and dialogue sentiment to estimate how engaging each scene is.

The project focuses on real-world AI system design â€” feature pipelines, multimodal fusion, and ML readiness â€” rather than toy model demos.

âœ¨ Key Features

ğŸ Scene Detection â€” Automatic segmentation of movies into timestamped scenes

ğŸ”Š Audio Emotion Analysis â€” Emotion confidence & intensity extracted from audio

ğŸ’¬ Text Intelligence (Subtitles) â€” Dialogue extraction, sentiment & keyword analysis

ğŸ§  Multimodal Fusion â€” Combines video, audio, and text signals per scene

ğŸ“Š Engagement Scoring â€” Scene-level engagement scores (baseline heuristic)

ğŸ—„ Database Persistence â€” Scene intelligence stored in PostgreSQL

âš™ï¸ Production-Ready Backend â€” Modular FastAPI architecture

ğŸ§  How CineMind Works
Movie Upload
   â†“
Scene Detection (Video)
   â†“
Audio Emotion Extraction
   â†“
Subtitle Parsing & NLP
   â†“
Multimodal Feature Fusion
   â†“
Scene-Level Engagement Scores


Each scene becomes a structured data record suitable for analytics or ML training.

ğŸ“¦ Example Output
{
  "scene_id": 3,
  "start_time": 42.1,
  "end_time": 58.9,
  "engagement_score": 81.6,
  "audio_confidence": 0.74,
  "text_sentiment": -0.62,
  "text_intensity": 0.85,
  "keywords": ["revenge", "threat"],
  "dialogue_count": 4
}

ğŸ›  Tech Stack
Backend & Data

Python

FastAPI

SQLAlchemy

PostgreSQL

Media Processing

FFmpeg

PySceneDetect

MoviePy

OpenCV

NLP

NLTK

Rule-based sentiment & keyword extraction

ğŸ—‚ Project Structure
backend/
 â””â”€â”€ app/
     â”œâ”€â”€ api/          # REST endpoints
     â”œâ”€â”€ services/     # Scene, audio, text, fusion logic
     â”œâ”€â”€ db/           # Database models & engine
     â”œâ”€â”€ schemas/      # Pydantic schemas
     â””â”€â”€ main.py
data/
 â”œâ”€â”€ raw_movies/
 â””â”€â”€ subtitles/

ğŸ“ˆ Project Status
Component	Status
Backend architecture	âœ… Complete
Scene detection	âœ… Complete
Audio emotion analysis	âœ… Complete (baseline)
Text extraction & NLP	âœ… Complete
Multimodal fusion	âœ… Complete
Engagement scoring	âœ… Complete (rule-based)
Database integration	âœ… Complete
ML model training	â³ Planned
Frontend dashboard	â³ Planned
ğŸ¤– Machine Learning Note

CineMind currently uses rule-based heuristics to generate engagement scores.

This is intentional:

Enables weakly supervised learning

Produces labeled data for future ML models

Mirrors how real-world ML pipelines are bootstrapped

No pretrained ML model is used yet.

ğŸš§ Limitations

Engagement scoring is heuristic (not learned)

Subtitle extraction depends on embedded subtitles

No frontend UI yet

Not optimized for large-scale production traffic

ğŸ”® Future Improvements

ML-based engagement prediction models

Shot-level and pacing analysis

Speech-to-text (Whisper) integration

React-based analytics dashboard

Distributed processing & scaling

ğŸ‘¤ Author

Apoorva Srivastava
B.Tech Computer Science
Focus: Backend Engineering, Multimodal AI Systems, ML Pipelines

ğŸ“„ License

MIT License â€” for educational and research use.

ğŸ¯ Why This Project Matters

CineMind demonstrates how real AI systems are engineered â€” from raw data ingestion to structured intelligence â€” the same way teams at Netflix, Meta, or Google approach multimodal problems.
